{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18bb4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T10:49:49.429012Z",
     "start_time": "2022-11-10T10:49:40.950622Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/data1/CLERMS/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b07ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spectra: 109734\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from matchms.importing import load_from_json\n",
    "import pickle\n",
    "from matchms.importing import load_from_mgf\n",
    "\n",
    "with open(data_path + \"train_1.pickle\", 'rb') as f:\n",
    "    train1 = pickle.load(f)\n",
    "with open(data_path +\"train_2.pickle\", 'rb') as f:\n",
    "    train2 = pickle.load(f)\n",
    "with open(data_path +\"test_1.pickle\", 'rb') as f:\n",
    "    test1 = pickle.load(f)\n",
    "with open(data_path +\"test_2.pickle\", 'rb') as f:\n",
    "    test2 = pickle.load(f)\n",
    "    \n",
    "spectrums = train1 + train2 + test1 + test2\n",
    "# spectrums = list(load_from_mgf(spectrums_filepath))\n",
    "print(\"number of spectra:\", len(spectrums))\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250d2523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T01:15:45.820183Z",
     "start_time": "2022-11-08T01:15:24.453850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining spectra: 109734\n",
      "Maximum number of peaks in one spectrum: 37922\n",
      "Number of spectra with > 1000 peaks: 5216\n",
      "Number of spectra with > 2000 peaks: 2099\n",
      "Number of spectra with > 5000 peaks: 639\n",
      "Careful: Number of spectra with < 10 peaks: 13422\n",
      "InChI=1S/C6H7O4P/c7-11(8,9)10-6-4-2-1-3-5-6/h1-5H,(H2,7,8,9)\n",
      "\n",
      "c(c1)ccc(c1)OP(O)(O)=O\n"
     ]
    }
   ],
   "source": [
    "spectrums = [s for s in spectrums if s is not None]\n",
    "print(\"Number of remaining spectra:\", len(spectrums))\n",
    "\n",
    "number_of_peaks = [len(spec.peaks) for spec in spectrums]\n",
    "print(\"Maximum number of peaks in one spectrum:\", np.max(number_of_peaks))\n",
    "print(\"Number of spectra with > 1000 peaks:\", np.sum(np.array(number_of_peaks) > 1000))\n",
    "print(\"Number of spectra with > 2000 peaks:\", np.sum(np.array(number_of_peaks) > 2000))\n",
    "print(\"Number of spectra with > 5000 peaks:\", np.sum(np.array(number_of_peaks) > 5000))\n",
    "print(\"Careful: Number of spectra with < 10 peaks:\", np.sum(np.array(number_of_peaks) < 10))\n",
    "\n",
    "ID = 2\n",
    "if spectrums[ID].get(\"inchi\") + spectrums[ID].get(\"smiles\"):\n",
    "    print(spectrums[ID].get(\"inchi\") + \"\\n\\n\" + spectrums[ID].get(\"smiles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602e3c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T01:24:52.993812Z",
     "start_time": "2022-11-08T01:15:45.825673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inchikeys (14char) in annotated dat: 15062\n",
      "有用的质谱数量： 109734 总的数量是 109734\n"
     ]
    }
   ],
   "source": [
    "def annotated(s):\n",
    "    return (s.get(\"inchi\") or s.get(\"smiles\")) and s.get(\"inchikey\")\n",
    "\n",
    "\n",
    "annotation_list = []\n",
    "for i, s in enumerate(spectrums):\n",
    "    if annotated(s):\n",
    "        annotation_list.append((i, s.get(\"inchi\"), s.get(\"smiles\"), s.get(\"inchikey\")))\n",
    "print(f\"Unique inchikeys (14char) in annotated dat: {len({x[3][:14] for x in annotation_list})}\")\n",
    "spectrums_annotated = [s for s in spectrums if annotated(s)]\n",
    "print(\"useful spectra nums：\", len(spectrums_annotated), \"all spectra nums\", len(spectrums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c25793f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T01:25:09.288309Z",
     "start_time": "2022-11-08T01:24:52.997044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCEYJYMNIQHPPK\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n",
      "\n",
      "most frequent: CC1(C)C(=O)C=C[C@@]2(C)[C@H]1C[C@@H](O)[C@]1(C)[C@@H]2CC[C@@]2(C)[C@H](c3ccoc3)OC(=O)[C@H]3O[C@]321\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "inchikeys_list = []\n",
    "for s in spectrums_annotated:\n",
    "    inchikeys_list.append(s.get(\"inchikey\"))\n",
    "\n",
    "inchikeys14_array = np.array([x[:14] for x in inchikeys_list])\n",
    "\n",
    "inchikeys14_unique = list({x[:14] for x in inchikeys_list})\n",
    "\n",
    "inchikey14 = inchikeys14_unique[12]\n",
    "print(inchikey14)\n",
    "\n",
    "idx = np.where(inchikeys14_array == inchikey14)[0]\n",
    "for i in idx:\n",
    "    print(spectrums_annotated[i].get(\"smiles\") + \"\\n\")\n",
    "\n",
    "print(\"most frequent:\", most_frequent([spectrums_annotated[i].get(\"smiles\") for i in idx]))\n",
    "\n",
    "inchi_list = []\n",
    "for s in spectrums_annotated:\n",
    "    inchi_list.append(s.get(\"inchi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835b0bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T01:30:47.560479Z",
     "start_time": "2022-11-08T01:25:09.291719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c4052935a44c9a1bde96a4fa52c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:28:38] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inchi_array = np.array(inchi_list)\n",
    "\n",
    "inchi_mapping = []\n",
    "ID_mapping = []\n",
    "inchikeys_unique = []\n",
    "for inchikey14 in inchikeys14_unique:\n",
    "    idx = np.where(inchikeys14_array == inchikey14)[0]\n",
    "    inchi = most_frequent([spectrums_annotated[i].get(\"inchi\") for i in idx])\n",
    "    inchi_mapping.append(inchi)\n",
    "    ID = idx[np.where(inchi_array[idx] == inchi)[0][0]]\n",
    "    ID_mapping.append(ID)\n",
    "\n",
    "    indd = inchikeys14_array[idx][0]\n",
    "    inchikeys_unique.append(indd)\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "metadata = pd.DataFrame(list(zip(inchikeys_unique, inchi_mapping, ID_mapping)), columns=[\"inchikey\", \"inchi\", \"ID\"])\n",
    "\n",
    "from matchms.filtering.add_fingerprint import add_fingerprint\n",
    "\n",
    "for i in tqdm(metadata.ID.values):\n",
    "    spectrums_annotated[i] = add_fingerprint(spectrums_annotated[i], fingerprint_type=\"daylight\", nbits=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4e205",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-08T01:24:03.611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fd980fac994661bfcfa182e4292bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(metadata.ID.values):\n",
    "    if np.any(np.isnan(spectrums_annotated[i].get(\"fingerprint\"))):\n",
    "        print(i)\n",
    "from matchms.similarity import FingerprintSimilarity\n",
    "\n",
    "spectrums_represent = [spectrums_annotated[i] for i in metadata.ID.values]\n",
    "\n",
    "similarity_measure = FingerprintSimilarity(similarity_measure=\"jaccard\")\n",
    "import numpy\n",
    "\n",
    "\n",
    "def jaccard_index(u, v):\n",
    "    u_or_v = numpy.bitwise_or(u != 0, v != 0)\n",
    "    u_and_v = numpy.bitwise_and(u != 0, v != 0)\n",
    "    jaccard_score = 0\n",
    "    if u_or_v.sum() != 0:\n",
    "        jaccard_score = numpy.float64(u_and_v.sum()) / numpy.float64(u_or_v.sum())\n",
    "    return jaccard_score\n",
    "\n",
    "\n",
    "scores_mol_similarity = similarity_measure.matrix(spectrums_represent, spectrums_represent)\n",
    "tanimoto_df = pd.DataFrame(scores_mol_similarity, columns=metadata.inchikey.values, index=metadata.inchikey.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dafb918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T02:36:56.276883Z",
     "start_time": "2022-10-24T02:32:27.407234Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/data1/CLERMS/data/ALL_GNPS_210125_positive_daylight_tanimoto_scores.pkl\",'wb') as f:\n",
    "    pickle.dump(tanimoto_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362b645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
