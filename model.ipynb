{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:08:29.976716Z",
     "start_time": "2023-01-04T07:08:28.181178Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools.trainer import TrainerCon\n",
    "from models.SinusoidalModel import SinSiameseModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tools.utils as uti\n",
    "from tools.con_tran_data import ConTranDataGen\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:08:31.495854Z",
     "start_time": "2023-01-04T07:08:29.981105Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import *\n",
    "\n",
    "import swifter\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:50.124965Z",
     "start_time": "2023-01-04T07:11:50.010318Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from rdkit import Chem\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from models.SinusoidalModel import SinSiameseModel\n",
    "import torch\n",
    "from matchms.filtering.add_fingerprint import add_fingerprint\n",
    "from matchms.similarity import FingerprintSimilarity\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import time\n",
    "\n",
    "plt.rc('font',family='Times New Roman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:52.149767Z",
     "start_time": "2023-01-04T07:11:50.889511Z"
    }
   },
   "outputs": [],
   "source": [
    "abspath = \"/data1/CLERMAS/\"\n",
    "score_name = 'daylight' \n",
    "score_df = pd.read_pickle(abspath + f\"data/ALL_GNPS_210125_positive_{score_name}_tanimoto_scores.pkl\") # 相似分数\n",
    "pth = abspath + \"dict/\" # model save path\n",
    "val_ratio = 0.2 # validation \n",
    "sim_loss =  30 # structual similarity loss weight\n",
    "epochs = 8\n",
    "project_size = 200 # the embedding size\n",
    "temperature = 0.05 # the temperature\n",
    "model_name = f\"pre_T{temperature}_sim_loss{sim_loss}_epochs{epochs}\"\n",
    "PRECURSOR_MZ = \"precursor_mz_new\"\n",
    "train_flag = 1 # means traing, if 0 means just predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:52.162834Z",
     "start_time": "2023-01-04T07:11:52.155534Z"
    }
   },
   "outputs": [],
   "source": [
    "model_results = pth + model_name\n",
    "if not os.path.exists(model_results):\n",
    "    os.mkdir(model_results)\n",
    "    os.mkdir(model_results + \"/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:53.992955Z",
     "start_time": "2023-01-04T07:11:53.988570Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:54.395977Z",
     "start_time": "2023-01-04T07:11:54.363905Z"
    }
   },
   "outputs": [],
   "source": [
    "def true_M(precursor_mz, adduct):\n",
    "    if adduct == \"0\" or adduct==\"[Cat]\" or adduct==\"[M+HFA+H]+\" or adduct==\"[M+HFA+NH4]+\":\n",
    "        return precursor_mz\n",
    "    elif adduct == \"[2M+Ca-H]+\":\n",
    "        return (precursor_mz-39)/2\n",
    "    elif adduct == \"[2M+Ca]2+\":\n",
    "        return precursor_mz-20\n",
    "    elif adduct == \"[2M+H+CH3CN]\":\n",
    "        return (precursor_mz-42 )/2\n",
    "    elif adduct == \"[2M+H]\":\n",
    "        return (precursor_mz-1)/2\n",
    "    elif adduct ==\"[2M+H]+\":\n",
    "        return (precursor_mz-1)/2\n",
    "    elif adduct ==\"[2M+K]+\":\n",
    "        return (precursor_mz-39)/2\n",
    "    elif adduct ==\"[2M+NH4]\":\n",
    "        return (precursor_mz-16)/2\n",
    "    elif adduct ==\"[2M+NH4]+\":\n",
    "        return (precursor_mz-16)/2\n",
    "    elif adduct ==\"[2M+Na]+\":\n",
    "        return (precursor_mz-23)/2\n",
    "    elif adduct==\"[2M-2H2O+H]+\":\n",
    "        return (precursor_mz+35)/2\n",
    "    elif adduct==\"[2M-H+2Na]+\":\n",
    "        return (precursor_mz-45)/2\n",
    "    elif adduct==\"[2M-H2O+H]+\":\n",
    "        return (precursor_mz+17)/2\n",
    "    elif adduct==\"[2M-H2O+Na]+\":\n",
    "        return (precursor_mz-5)/2\n",
    "    elif adduct==\"[3M+Ca-H]+\":\n",
    "        return (precursor_mz-39)/3\n",
    "    elif adduct==\"[3M+Ca]2+\":\n",
    "        return (precursor_mz-40)/3\n",
    "    elif adduct==\"[3M+H]\" or adduct==\"[3M+H]+\":\n",
    "        return (precursor_mz-1)/3\n",
    "    elif adduct==\"[3M+K]+\":\n",
    "        return (precursor_mz-39)/3\n",
    "    elif adduct==\"[3M+NH4]\" or adduct==\"[3M+NH4]+\":\n",
    "        return (precursor_mz-18)/3\n",
    "    elif adduct==\"[3M+Na]\" or adduct==\"[3M+Na]+\":\n",
    "        return (precursor_mz-23)/3\n",
    "    elif adduct==\"[4M+Ca]2+\":\n",
    "        return (precursor_mz*2-40)/4\n",
    "    elif adduct==\"[M+15]+\":\n",
    "        return precursor_mz-15\n",
    "    elif adduct==\"[M+2H+2]\" or adduct==\"[M+2H]2+\":\n",
    "        return precursor_mz*2 -2\n",
    "    elif adduct==\"[M+2Na-H]+\":\n",
    "        return precursor_mz - 45\n",
    "    elif adduct==\"[M+2Na]\":\n",
    "        return precursor_mz - 46\n",
    "    elif adduct==\"[M+3H]3+\":\n",
    "        return precursor_mz*3 -3\n",
    "    elif adduct==\"[M+ACN+NH4]+\":\n",
    "        return precursor_mz - 59\n",
    "    elif adduct==\"[M+ACN+H]+\":\n",
    "        return precursor_mz - 42\n",
    "    elif adduct==\"[M+CH3OH+H]\":\n",
    "        return precursor_mz-33\n",
    "    elif adduct==\"[M+Ca-H]+\":\n",
    "        return precursor_mz-39\n",
    "    elif adduct==\"[M+Ca]2+\":\n",
    "        return precursor_mz*2-40\n",
    "    elif adduct==\"[M+Cl]-\":\n",
    "        return precursor_mz-35.5\n",
    "    elif adduct==\"[M+H+C2H6OS]\":\n",
    "        return precursor_mz-79\n",
    "    elif adduct==\"[M+H+CH3CN]\":\n",
    "        return precursor_mz-42\n",
    "    elif adduct==\"[M+H+CH3OH]\":\n",
    "        return precursor_mz-37\n",
    "    elif adduct==\"[M+H+HCOOH]\":\n",
    "        return precursor_mz-47\n",
    "    elif adduct==\"[M+H+Na]2+\":\n",
    "        return 2*precursor_mz-24\n",
    "    elif adduct==\"[M+H-(C12H20O9)]+\":\n",
    "        return precursor_mz+307\n",
    "    elif adduct==\"[M+H-2H2O]+\":\n",
    "        return precursor_mz + 35\n",
    "    elif adduct==\"[M+H-99]\":\n",
    "        return precursor_mz+98\n",
    "    elif adduct==\"[M+H-C9H10O5]\":\n",
    "        return precursor_mz +197\n",
    "    elif adduct==\"[M+H-H20]\":\n",
    "        return precursor_mz+17\n",
    "    elif adduct==\"[M+H-NH3]\":\n",
    "        return precursor_mz+14\n",
    "    elif adduct==\"[M+HCl]\":\n",
    "        return precursor_mz-36.5\n",
    "    elif adduct==\"[M+H]+\":\n",
    "        return precursor_mz-1\n",
    "    elif adduct==\"[M+K]+\":\n",
    "        return precursor_mz-39\n",
    "    elif adduct==\"[M+Li]+\":\n",
    "        return precursor_mz-7\n",
    "    elif adduct==\"[M+NH3]\":\n",
    "        return precursor_mz-15\n",
    "    elif adduct==\"[M+NH4-H2O]\":\n",
    "        return precursor_mz+2\n",
    "    elif adduct==\"[M+NH4]+\":\n",
    "        return precursor_mz-16\n",
    "    elif adduct==\"[M+Na+CH3CN]\":\n",
    "        return precursor_mz-64\n",
    "    elif adduct==\"[M+Na]+\":\n",
    "        return precursor_mz-23\n",
    "    elif adduct==\"[M-2(H2O)+H]\" or adduct==\"[M-2H2O+H]+\":\n",
    "        return precursor_mz+35\n",
    "    elif adduct==\"[M-2H2O+2H]2+\":\n",
    "        return precursor_mz+34\n",
    "    elif adduct==\"[M-2H2O+NH4]+\":\n",
    "        return precursor_mz+18\n",
    "    elif adduct==\"[M-3H2O+2H]2+\":\n",
    "        return precursor_mz*2-2+3*18\n",
    "    elif adduct==\"[M-3H2O+H]\" or adduct==\"[M-3H2O+H]+\":\n",
    "        return precursor_mz+3*18-1\n",
    "    elif adduct==\"[M-4H2O+H]+\":\n",
    "        return precursor_mz+4*18-1\n",
    "    elif adduct==\"[M-5H2O+H]+\":\n",
    "        return precursor_mz+5*18-1\n",
    "    elif adduct==\"[M-C6H10O5+H]\":\n",
    "        return precursor_mz+12*6+10+16*5-1\n",
    "    elif adduct==\"[M-H+Li]+\":\n",
    "        return precursor_mz-6\n",
    "    elif adduct==\"[M-H+Na]+\":\n",
    "        return precursor_mz-22\n",
    "    elif adduct==\"[M-H2O+H]+\":\n",
    "        return precursor_mz+17\n",
    "    elif adduct==\"[M-H2O+NH4]+\":\n",
    "        return precursor_mz\n",
    "    elif adduct==\"[M-H2O]\":\n",
    "        return precursor_mz + 18\n",
    "    elif adduct==\"[M-H]-\":\n",
    "        return precursor_mz+1\n",
    "    elif adduct==\"[M-MeOH+H]\":\n",
    "        return precursor_mz\n",
    "    elif adduct==\"[M2+H]\":\n",
    "        return (precursor_mz-1)/2\n",
    "    elif adduct==\"[M2+Na]\":\n",
    "        return (precursor_mz-23)/2\n",
    "    elif adduct==\"[M2Br81+H]\":\n",
    "        return (precursor_mz-1)/2\n",
    "    elif adduct==\"[MBr81+H]\":\n",
    "        return precursor_mz-1\n",
    "    elif adduct==\"[MCl+H]\":\n",
    "        return precursor_mz -1\n",
    "    elif adduct==\"[MCl37+H]\":\n",
    "        return precursor_mz-1\n",
    "    elif adduct==\"[MS+H]\":\n",
    "        return precursor_mz -1\n",
    "    elif adduct==\"[M]+\" or adduct==\"[M]-\":\n",
    "        return precursor_mz\n",
    "    else:\n",
    "        return precursor_mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:54.735985Z",
     "start_time": "2023-01-04T07:11:54.714342Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trans_vec(x, dim=100):\n",
    "    intensity_list = np.sqrt(x['intensities'])\n",
    "    intensity_list = intensity_list/np.max(intensity_list)\n",
    "    mzlist = x['mz']\n",
    "    n_peaks = len(intensity_list)\n",
    "    descend_order = intensity_list.argsort()[::-1]\n",
    "    mzlist = mzlist[descend_order]\n",
    "    intensity_list = intensity_list[descend_order]\n",
    "    if n_peaks>dim:\n",
    "        return np.stack([mzlist[:dim],intensity_list[:dim]]) # keep the first n peaks according to their intensity value\n",
    "    else: # we pad it with zero if the number of peaks less than dim \n",
    "        intensity_list = np.pad(intensity_list, (0, dim-n_peaks), 'constant', constant_values=0)\n",
    "        mzlist = np.pad(mzlist, (0, dim-n_peaks), 'constant', constant_values=0)\n",
    "        return np.stack([mzlist,intensity_list])\n",
    "\n",
    "def mgf2df(mgf_path,bin=True):    \n",
    "    with open(mgf_path,'rb') as f:\n",
    "        mgf = pickle.load(f) \n",
    "    data_collect = []\n",
    "    for i in tqdm(mgf):\n",
    "        if i:\n",
    "            temp = {}\n",
    "            temp['mz'] = i.mz\n",
    "            temp['intensities']=i.intensities\n",
    "            temp['inchikey'] = i.metadata.get(\"inchikey\",\"-1\")\n",
    "            temp['precursor_mz'] = i.metadata.get(\"precursor_mz\",0)\n",
    "            temp['inchikey14'] = i.get(\"inchikey14\",'0')\n",
    "            temp['source_instrument'] = i.get('source_instrument','N/A-N/A')\n",
    "            temp['adduct'] = i.get('adduct','0')\n",
    "            temp['charge'] = i.get('charge')\n",
    "            temp['smile'] = i.get('smiles')\n",
    "            temp['precursor_mz_new'] = true_M(i.metadata.get(\"precursor_mz\",0), i.get('adduct','0'))\n",
    "            data_collect.append(temp)\n",
    "\n",
    "    data = pd.DataFrame(data_collect)\n",
    "    data[\"vec\"] = data.apply(get_trans_vec, axis=1)\n",
    "    data['m_id'] = data['inchikey14']\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:55.011297Z",
     "start_time": "2023-01-04T07:11:55.000397Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(datapath, flag, bin):\n",
    "    data = mgf2df(datapath, bin=bin)\n",
    "    data[\"flag\"] = flag\n",
    "   \n",
    "    data[\"precursor_mz\"] = data[\"precursor_mz\"]/1000\n",
    "    data[\"precursor_mz_new\"] = data[\"precursor_mz_new\"]/1000\n",
    "    data[\"charge\"] = data['charge'].astype(int)\n",
    "\n",
    "    cat_columns = ['adduct','source_instrument'] \n",
    "    for co in cat_columns:\n",
    "        lb = LabelEncoder()\n",
    "        lb.classes_ = np.load(co+\"_classes.npy\", allow_pickle=True)\n",
    "        data[co] = lb.transform(data[co])\n",
    "\n",
    "    data['index'] = list(range(data.shape[0]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:11:55.245499Z",
     "start_time": "2023-01-04T07:11:55.231458Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predict_results(data, model):\n",
    "    predict_array = [np.stack(data['vec'].values),data['source_instrument'].values,data['charge'].values,np.reshape(data[PRECURSOR_MZ].values,(-1,1)),data['adduct'].values]\n",
    "    train_result = []\n",
    "    batch_size = 32\n",
    "    for i in tqdm(range(0, data.shape[0],batch_size)):\n",
    "        f = predict_array[0][i:i+batch_size] \n",
    "        t = predict_array[1][i:i+batch_size] \n",
    "        k = predict_array[2][i:i+batch_size] \n",
    "        l = predict_array[3][i:i+batch_size] \n",
    "        a = predict_array[4][i:i+batch_size] \n",
    "        m = [f,t,k,l,a]\n",
    "\n",
    "        train_result.append(model(m).cpu().detach().numpy())\n",
    "    predict_array_hidden = np.vstack(train_result)\n",
    "    predict_array_hidden_norm = predict_array_hidden / np.linalg.norm(predict_array_hidden,axis=1).reshape(predict_array_hidden.shape[0],1)\n",
    "    print(\"the data size ：\", data.shape[0])\n",
    "    return predict_array[0],predict_array_hidden,predict_array_hidden_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:14:09.307906Z",
     "start_time": "2023-01-04T07:11:56.327636Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train1 = load_data(abspath+ \"data/\" + \"train_1.pickle\",'train_1',False)\n",
    "data_train2 = load_data(abspath+ \"data/\" + \"train_2.pickle\",'train_2',False)\n",
    "data_test1 = load_data(abspath+ \"data/\" + \"test_1.pickle\",'test_1',False)\n",
    "data_test2 = load_data(abspath+ \"data/\" + \"test_2.pickle\",'test_2',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:17:03.927429Z",
     "start_time": "2023-01-04T07:17:03.712282Z"
    }
   },
   "outputs": [],
   "source": [
    "data_combine_all = pd.concat([data_train1,data_train2,data_test1,data_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:18:06.077930Z",
     "start_time": "2023-01-04T07:17:03.931400Z"
    }
   },
   "outputs": [],
   "source": [
    "# the data_index is a dict, and the key is inchikey, and the value is mass_spectrum instrument charge adduct, etc.\n",
    "data_index = defaultdict(list)\n",
    "for i in tqdm(range(data_train1.shape[0])):\n",
    "    data_index[data_train1.iloc[i]['m_id']].append([data_train1.iloc[i]['vec'],data_train1.iloc[i]['source_instrument'],data_train1.iloc[i]['charge'],data_train1.iloc[i][PRECURSOR_MZ],data_train1.iloc[i]['adduct']])\n",
    "\n",
    "# split the train and test\n",
    "inchikey14_unique = data_train1[\"m_id\"].unique()\n",
    "inchikey14 = inchikey14_unique\n",
    "\n",
    "l = len(inchikey14)\n",
    "keyvalindex = np.random.choice(np.arange(l),int(val_ratio*l),replace=False) \n",
    "keyval = inchikey14[keyvalindex]\n",
    "keytrain = np.delete(inchikey14,keyvalindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:18:08.136612Z",
     "start_time": "2023-01-04T07:18:06.080949Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the data used for train\n",
    "dtype = torch.float32\n",
    "score_index = score_df.index.values\n",
    "score_dict = dict(zip(score_index,np.arange(len(score_index))))\n",
    "train_data = ConTranDataGen(data_index, keytrain, score_dict,nround=10,nviews=2,augment=False)\n",
    "val_data = ConTranDataGen(data_index, keyval,score_dict)\n",
    "model = SinSiameseModel(100, project_size=project_size).to(dtype).to(\"cuda\")\n",
    "dataloader_train = DataLoader(train_data,256,shuffle=True)\n",
    "dataloader_val = DataLoader(val_data,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:08:43.874763Z",
     "start_time": "2023-01-04T07:08:43.874743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_flag:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=5e-5,weight_decay=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 100, 0.7)\n",
    "\n",
    "    trainer = TrainerCon(model, \n",
    "                            [dataloader_train,dataloader_val], \n",
    "                            score_df,\n",
    "                            optimizer,epochs, \n",
    "                            scheduler,\n",
    "                            dtype,\n",
    "                            pth = pth,\n",
    "                            model_name = model_name,\n",
    "                            sim_ratio = sim_loss,\n",
    "                            temperature = temperature)\n",
    "    trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:18:08.153863Z",
     "start_time": "2023-01-04T07:18:08.145231Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_results = model_results + \"/models/best.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T07:18:09.717506Z",
     "start_time": "2023-01-04T07:18:08.733334Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "dtype = torch.float32\n",
    "model = SinSiameseModel(100,project_size=project_size).to(device).to(dtype)\n",
    "model.load_state_dict(torch.load(best_model_results))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T08:10:54.302934Z",
     "start_time": "2022-12-20T08:08:48.616407Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_all_array, data_all_array_hidden,data_all_array_hidden_norm = get_predict_results(data_combine_all, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4654e147d6fe676f31a9f86e2485eea716359f8709963986145f7c2d0088ba8c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.033px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
